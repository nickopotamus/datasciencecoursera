tdm_ngram_df <- tdm_ngram_df[order(-tdm_ngram_df$Count), , drop = FALSE]
tdm_ngram_df
}
# Calculate N-Grams
tdm_1gram <- tdm_Ngram(cleanSample, 1)
tdm_2gram <- tdm_Ngram(cleanSample, 2)
tdm_3gram <- tdm_Ngram(cleanSample, 3)
tdm_4gram <- tdm_Ngram(cleanSample, 4)
# Extract term-count tables from N-Grams and sort
tdm_1gram_df <- ngram_sorted_df(tdm_1gram)
tdm_2gram_df <- ngram_sorted_df(tdm_2gram)
tdm_3gram_df <- ngram_sorted_df(tdm_3gram)
tdm_4gram_df <- ngram_sorted_df(tdm_4gram)
# Save data frames into r-compressed files
quadgram <- data.frame(rows = rownames(tdm_4gram_df), count = tdm_4gram_df$Count)
quadgram$rows <- as.character(quadgram$rows)
quadgram_split <- strsplit(as.character(quadgram$rows),split = " ")
quadgram <- transform(quadgram,
first = sapply(quadgram_split,"[[",1),
second = sapply(quadgram_split,"[[",2),
third = sapply(quadgram_split,"[[",3),
fourth = sapply(quadgram_split,"[[",4))
quadgram <- data.frame(unigram = quadgram$first,
bigram = quadgram$second,
trigram = quadgram$third,
quadgram = quadgram$fourth,
freq = quadgram$count,stringsAsFactors=FALSE)
write.csv(quadgram[quadgram$freq > 1,],"./data/quadgram.csv",row.names=F)
quadgram <- read.csv("./data/quadgram.csv",stringsAsFactors = F)
saveRDS(quadgram,"./app/quadgram.RData")
trigram <- data.frame(rows=rownames(tdm_3gram_df),count=tdm_3gram_df$Count)
trigram$rows <- as.character(trigram$rows)
trigram_split <- strsplit(as.character(trigram$rows),split=" ")
trigram <- transform(trigram,
first = sapply(trigram_split,"[[",1),
second = sapply(trigram_split,"[[",2),
third = sapply(trigram_split,"[[",3))
rm(quadgram, quadgram_split, tdm_1gram, tdm_2gram, tdm_3gram, tdm_4gram, tdm_1gram_df, tdm_2gram_df, tdm_3gram_df, tdm_4gram_df, trigram, trigram_split)
set.seed(69)
portion <- .03
sampletext <- function(textbody, portion) {
taking <- sample(1:length(textbody), length(textbody)*portion)
Sampletext <- textbody[taking]
Sampletext
}
sampleTwitter <- sampletext(twitter, portion)
sampleNews <- sampletext(news, portion)
sampleBlogs <- sampletext(blogs, portion)
#sampleTwitter <- twitter[sample(1:length(twitter),sample_size)]
#sampleNews <- news[sample(1:length(news),sample_size)]
#sampleBlogs <- blogs[sample(1:length(blogs),sample_size)]
textSample <- c(sampleTwitter,sampleNews,sampleBlogs)
writeLines(textSample, "./data/textsample/textSample.txt")
#rm(sampleTwitter, sampleNews, sampleBlogs)
#rm(twitter, news, blogs)
# Data Cleansing
cleanSample <- VCorpus(DirSource("./data/textSample", encoding = "UTF-8"))
removeURL <- function(x) gsub("http[[:alnum:]]*", "", x)
profanityWords <- readLines("./data/profanityWords.txt")
cleansing <- function (textcp) {
textcp <- tm_map(textcp, content_transformer(tolower))
textcp <- tm_map(textcp, content_transformer(removePunctuation), preserve_intra_word_dashes = TRUE)
textcp <- tm_map(textcp, stripWhitespace)
textcp <- tm_map(textcp, content_transformer(removeNumbers))
textcp <- tm_map(textcp, content_transformer(removeURL))
textcp <- tm_map(textcp, removeWords, stopwords("english"))
textcp <- tm_map(textcp, removeWords, profanityWords)
textcp
}
cleanSample <- cleansing(cleanSample)
saveRDS(cleanSample, file = "./data/cleanSample.Rds")
rm(textSample, profanityWords)
# Function to make N-grams
tdm_Ngram <- function (textcp, n) {
NgramTokenizer <- function(x) {
RWeka::NGramTokenizer(x,
RWeka::Weka_control(min = n,
max = n,
delimiters = " \\r\\n\\t.,;:\"()?!")
)
}
tdm_ngram <- TermDocumentMatrix(textcp, control = list(tokenizer = NgramTokenizer))
tdm_ngram
}
# Function to extract and sort N-grams
ngram_sorted_df <- function (tdm_ngram) {
tdm_ngram_m <- as.matrix(tdm_ngram)
tdm_ngram_df <- as.data.frame(tdm_ngram_m)
colnames(tdm_ngram_df) <- "Count"
tdm_ngram_df <- tdm_ngram_df[order(-tdm_ngram_df$Count), , drop = FALSE]
tdm_ngram_df
}
# Calculate N-Grams
tdm_1gram <- tdm_Ngram(cleanSample, 1)
tdm_2gram <- tdm_Ngram(cleanSample, 2)
tdm_3gram <- tdm_Ngram(cleanSample, 3)
tdm_4gram <- tdm_Ngram(cleanSample, 4)
# Extract term-count tables from N-Grams and sort
tdm_1gram_df <- ngram_sorted_df(tdm_1gram)
tdm_2gram_df <- ngram_sorted_df(tdm_2gram)
tdm_3gram_df <- ngram_sorted_df(tdm_3gram)
tdm_4gram_df <- ngram_sorted_df(tdm_4gram)
# Save data frames into r-compressed files
quadgram <- data.frame(rows = rownames(tdm_4gram_df), count = tdm_4gram_df$Count)
quadgram$rows <- as.character(quadgram$rows)
quadgram_split <- strsplit(as.character(quadgram$rows),split = " ")
quadgram <- transform(quadgram,
first = sapply(quadgram_split,"[[",1),
second = sapply(quadgram_split,"[[",2),
third = sapply(quadgram_split,"[[",3),
fourth = sapply(quadgram_split,"[[",4))
quadgram <- data.frame(unigram = quadgram$first,
bigram = quadgram$second,
trigram = quadgram$third,
quadgram = quadgram$fourth,
freq = quadgram$count,stringsAsFactors=FALSE)
write.csv(quadgram[quadgram$freq > 1,],"./data/quadgram.csv",row.names=F)
quadgram <- read.csv("./data/quadgram.csv",stringsAsFactors = F)
saveRDS(quadgram,"./app/quadgram.RData")
trigram <- data.frame(rows=rownames(tdm_3gram_df),count=tdm_3gram_df$Count)
trigram$rows <- as.character(trigram$rows)
trigram_split <- strsplit(as.character(trigram$rows),split=" ")
trigram <- transform(trigram,
first = sapply(trigram_split,"[[",1),
second = sapply(trigram_split,"[[",2),
third = sapply(trigram_split,"[[",3))
trigram <- data.frame(unigram = trigram$first,
bigram = trigram$second,
trigram = trigram$third,
freq = trigram$count,stringsAsFactors=FALSE)
write.csv(trigram[trigram$freq > 1,],"./data/trigram.csv",row.names=F)
trigram <- read.csv("./data/trigram.csv",stringsAsFactors = F)
saveRDS(trigram,"./app/trigram.RData")
bigram <- data.frame(rows=rownames(tdm_2gram_df),count=tdm_2gram_df$Count)
bigram$rows <- as.character(bigram$rows)
bigram_split <- strsplit(as.character(bigram$rows),split=" ")
bigram <- transform(bigram,
first = sapply(bigram_split,"[[",1),
second = sapply(bigram_split,"[[",2))
bigram <- data.frame(unigram = bigram$first,
bigram = bigram$second,
freq = bigram$count,stringsAsFactors=FALSE)
write.csv(bigram[bigram$freq > 1,],"./data/bigram.csv",row.names=F)
bigram <- read.csv("./data/bigram.csv",stringsAsFactors = F)
saveRDS(bigram,"./app/bigram.RData")
unigram <- data.frame(rows=rownames(tdm_1gram_df),count=tdm_1gram_df$Count)
unigram$rows <- as.character(unigram$rows)
unigram_split <- strsplit(as.character(unigram$rows),split=" ")
unigram <- transform(unigram,
first = sapply(unigram_split,"[[",1))
unigram <- data.frame(unigram = unigram$first,
freq = unigram$count,
stringsAsFactors=FALSE)
write.csv(unigram[unigram$freq > 1,],"./data/unigram.csv",row.names=F)
unigram <- read.csv("./data/unigram.csv",stringsAsFactors = F)
saveRDS(unigram,"./app/unigram.RData")
shiny::runApp('app')
runApp('app')
bg <- readRDS("bigram.RData")
setwd("~/Dropbox/git/datasciencecoursera/10_Capstone/app")
runApp()
bg <- readRDS("bigram.RData")
head(bg)
names(bg)[names(bg) == 'word1'] <- 'w1'
names(bg)[names(bg) == 'word2'] <- 'w2'
head(bg)
names(bg)
bg <- readRDS("bigram.RData")
names(bg)[names(bg) == 'word1'] <- 'w1'
names(bg)[names(bg) == 'word2'] <- 'w2'
tg <- readRDS("trigram.RData")
names(tg)[names(tg) == 'word1'] <- 'w1'
names(tg)[names(tg) == 'word2'] <- 'w2'
names(tg)[names(tg) == 'word3'] <- 'w3'
qd <- readRDS("quadgram.RData")
names(qd)[names(qd) == 'word1'] <- 'w1'
names(qd)[names(qd) == 'word2'] <- 'w2'
names(qd)[names(qd) == 'word3'] <- 'w3'
names(qd)[names(qd) == 'word4'] <- 'w4'
message <- "" ## cleaning message
predictWord <- function(the_word) {
# Clean input word
word_add <- stripWhitespace(
removeNumbers(
removePunctuation(
tolower(the_word),
preserve_intra_word_dashes = TRUE)))
the_word <- strsplit(word_add, " ")[[1]]
n <- length(the_word)
# Check bigram
if (n == 1) {the_word <- as.character(tail(the_word,1))functionBigram(the_word)}
# Check trigram
else if (n == 2) {the_word <- as.character(tail(the_word,2)); functionTrigram(the_word)}
# Check quadgram
else if (n >= 3) {the_word <- as.character(tail(the_word,3)); functionQuadgram(the_word)}
}
## Capstone: Coursera Data Science
## Final Project
## joseantonio
# SHINY SERVER
library(shiny); library(stringr); library(tm)
# Loading bigram, trigram and quadgram frequencies words matrix frequencies
bg <- readRDS("bigram.RData"); tg <- readRDS("trigram.RData"); qd <- readRDS("quadgram.RData")
names(bg)[names(bg) == 'word1'] <- 'w1'; names(bg)[names(bg) == 'word2'] <- 'w2';
names(tg)[names(tg) == 'word1'] <- 'w1'; names(tg)[names(tg) == 'word2'] <- 'w2'; names(tg)[names(tg) == 'word3'] <- 'w3';
names(qd)[names(qd) == 'word1'] <- 'w1'; names(qd)[names(qd) == 'word2'] <- 'w2'; names(qd)[names(qd) == 'word3'] <- 'w3'
names(qd)[names(qd) == 'word4'] <- 'w4';
message <- "" ## cleaning message
## Function predicting the next word
predictWord <- function(the_word) {
word_add <- stripWhitespace(removeNumbers(removePunctuation(tolower(the_word),preserve_intra_word_dashes = TRUE)))
# testing print("word_add")
the_word <- strsplit(word_add, " ")[[1]]
# testing print("the_word")
n <- length(the_word)
# testing print(n)
########### check Bigram
if (n == 1) {the_word <- as.character(tail(the_word,1)); functionBigram(the_word)}
################ check trigram
else if (n == 2) {the_word <- as.character(tail(the_word,2)); functionTrigram(the_word)}
############### check quadgram
else if (n >= 3) {the_word <- as.character(tail(the_word,3)); functionQuadgram(the_word)}
}
########################################################################
functionBigram <- function(the_word) {
# testing print(the_word)
if (identical(character(0),as.character(head(bg[bg$w1 == the_word[1], 2], 1)))) {
# testing print(bg$w1)
message<<-"If no word found the most used pronoun 'it' in English will be returned"
as.character(head("it",1))
}
else {
message <<- "Trying to Predict the Word using Bigram Freqeuncy Matrix  "
as.character(head(bg[bg$w1 == the_word[1],2], 1))
# testing print of bg$w1, the_word[1]
}
}
########################################################################
functionTrigram <- function(the_word) {
# # testing print(the_word)
if (identical(character(0),as.character(head(tg[tg$w1 == the_word[1]
& tg$w2 == the_word[2], 3], 1)))) {
as.character(predictWord(the_word[2]))
# testing print tg$w1, tg$w2, the_word[1], the_word[2]
}
else {
message<<- "Trying to Predict the Word using Trigram Fruequency Matrix "
as.character(head(tg[tg$w1 == the_word[1]
& tg$w2 == the_word[2], 3], 1))
# testing print of tg$w1, tg$w2, the_word[1], the_word[2]
}
}
########################################################################
functionQuadgram <- function(the_word) {
# testing print(the_word)
if (identical(character(0),as.character(head(qd[qd$w1 == the_word[1]
& qd$w2 == the_word[2]
& qd$w3 == the_word[3], 4], 1)))) {
# testing print of qd$w1, qd$w2, qd#w3, the_word[1], the_word[2], the_word3
as.character(predictWord(paste(the_word[2],the_word[3],sep=" ")))
}
else {
message <<- "Trying to Predict the Word using Quadgram Frequency Matrix"
as.character(head(qd[qd$w1 == the_word[1]
& qd$w2 == the_word[2]
& qd$w3 == the_word[3], 4], 1))
# testing print of qd$w1, qd$w2, qd#w3, the_word[1], the_word[2], the_word3
}
}
#################################################
## ShineServer code to call the function predictWord
shinyServer(function(input, output) {
output$prediction <- renderPrint({
result <- predictWord(input$inputText)
output$sentence2 <- renderText({message})
result
});
output$sentence1 <- renderText({
input$inputText});
}
)
# Set up shiny server
library(shiny)
library(stringr)
library(tm)
# Load n-gram frequencies words matrixes
bg <- readRDS("bigram.RData")
names(bg)[names(bg) == 'word1'] <- 'w1'
names(bg)[names(bg) == 'word2'] <- 'w2'
tg <- readRDS("trigram.RData")
names(tg)[names(tg) == 'word1'] <- 'w1'
names(tg)[names(tg) == 'word2'] <- 'w2'
names(tg)[names(tg) == 'word3'] <- 'w3'
qd <- readRDS("quadgram.RData")
names(qd)[names(qd) == 'word1'] <- 'w1'
names(qd)[names(qd) == 'word2'] <- 'w2'
names(qd)[names(qd) == 'word3'] <- 'w3'
names(qd)[names(qd) == 'word4'] <- 'w4'
message <- "" ## cleaning message
# Function to predict the next word
predictWord <- function(the_word) {
# Clean input word
word_add <- stripWhitespace(
removeNumbers(
removePunctuation(
tolower(the_word),
preserve_intra_word_dashes = TRUE)))
the_word <- strsplit(word_add, " ")[[1]]
n <- length(the_word)
# Check bigram
if (n == 1) {the_word <- as.character(tail(the_word,1))functionBigram(the_word)}
# Check trigram
else if (n == 2) {the_word <- as.character(tail(the_word,2)); functionTrigram(the_word)}
# Check quadgram
else if (n >= 3) {the_word <- as.character(tail(the_word,3)); functionQuadgram(the_word)}
}
# Bigram finding function
functionBigram <- function(the_word) {
if (identical(character(0),as.character(head(bg[bg$w1 == the_word[1], 2], 1)))) {
message<<-"If no word found the most used pronoun 'it' will be returned"
as.character(head("it",1))
}
else {
message <<- "Trying to predict the next word using bigram frequency matrix"
as.character(head(bg[bg$w1 == the_word[1],2], 1))
}
}
# Trigram finding function
functionTrigram <- function(the_word) {
if (identical(character(0),as.character(head(tg[tg$w1 == the_word[1]
& tg$w2 == the_word[2], 3], 1)))) {
as.character(predictWord(the_word[2]))
}
else {
message <<- "Trying to predict the next word using trigram frequency matrix"
as.character(head(tg[tg$w1 == the_word[1]
& tg$w2 == the_word[2], 3], 1))
}
}
# Quadgram finding function
functionQuadgram <- function(the_word) {
if (identical(character(0),as.character(head(qd[qd$w1 == the_word[1]
& qd$w2 == the_word[2]
& qd$w3 == the_word[3], 4], 1)))) {
as.character(predictWord(paste(the_word[2],the_word[3],sep=" ")))
}
else {
message <<- "Trying to predict the next word using quadgram frequency matrix"
as.character(head(qd[qd$w1 == the_word[1]
& qd$w2 == the_word[2]
& qd$w3 == the_word[3], 4], 1))
}
}
# Shiney server code to call predictWord
shinyServer(function(input, output) {
output$prediction <- renderPrint({
result <- predictWord(input$inputText)
output$sentence2 <- renderText({message})
result
});
output$sentence1 <- renderText({
input$inputText});
}
)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
# Setup
rm(list = ls())
options(java.parameters = "-Xmx8000m") # Deals w/ Java heap space error)
setwd("~/Dropbox/git/datasciencecoursera/10_Capstone")
library(NLP)
library(tm)
library(rJava)
library(RWeka)
# Import raw data
blogs <-   readLines(file("./final/en_US/en_US.blogs.txt", open = "rb"),
encoding = "UTF-8", skipNul=TRUE)
news <-    readLines(file("./final/en_US/en_US.news.txt", open = "rb"),
encoding = "UTF-8", skipNul=TRUE)
twitter <- readLines(file("./final/en_US/en_US.twitter.txt", open = "rb"),
encoding = "UTF-8",skipNul=TRUE)
# Sampling to make data manageable
set.seed(69)
portion <- .03
sampletext <- function(textbody, portion) {
taking <- sample(1:length(textbody), length(textbody)*portion)
Sampletext <- textbody[taking]
Sampletext
}
sampleTwitter <- sampletext(twitter, portion)
sampleNews <- sampletext(news, portion)
sampleBlogs <- sampletext(blogs, portion)
textSample <- c(sampleTwitter,sampleNews,sampleBlogs)
writeLines(textSample, "./data/textsample/textSample.txt")
rm(sampleTwitter, sampleNews, sampleBlogs)
rm(twitter, news, blogs)
# Data Cleansing
cleanSample <- VCorpus(DirSource("./data/textSample", encoding = "UTF-8"))
removeURL <- function(x) gsub("http[[:alnum:]]*", "", x)
profanityWords <- readLines("./data/profanityWords.txt")
cleansing <- function (textcp) {
textcp <- tm_map(textcp, content_transformer(tolower))
textcp <- tm_map(textcp, content_transformer(removePunctuation), preserve_intra_word_dashes = TRUE)
textcp <- tm_map(textcp, stripWhitespace)
textcp <- tm_map(textcp, content_transformer(removeNumbers))
textcp <- tm_map(textcp, content_transformer(removeURL))
# textcp <- tm_map(textcp, removeWords, stopwords("english"))
textcp <- tm_map(textcp, removeWords, profanityWords)
textcp
}
cleanSample <- cleansing(cleanSample)
saveRDS(cleanSample, file = "./data/cleanSample.Rds")
rm(textSample, profanityWords)
# Function to make N-grams
tdm_Ngram <- function (textcp, n) {
NgramTokenizer <- function(x) {
RWeka::NGramTokenizer(x,
RWeka::Weka_control(min = n,
max = n,
delimiters = " \\r\\n\\t.,;:\"()?!")
)
}
tdm_ngram <- TermDocumentMatrix(textcp, control = list(tokenizer = NgramTokenizer))
tdm_ngram
}
# Function to extract and sort N-grams
ngram_sorted_df <- function (tdm_ngram) {
tdm_ngram_m <- as.matrix(tdm_ngram)
tdm_ngram_df <- as.data.frame(tdm_ngram_m)
colnames(tdm_ngram_df) <- "Count"
tdm_ngram_df <- tdm_ngram_df[order(-tdm_ngram_df$Count), , drop = FALSE]
tdm_ngram_df
}
# Calculate N-Grams
tdm_1gram <- tdm_Ngram(cleanSample, 1)
tdm_2gram <- tdm_Ngram(cleanSample, 2)
tdm_3gram <- tdm_Ngram(cleanSample, 3)
tdm_4gram <- tdm_Ngram(cleanSample, 4)
# Extract term-count tables from N-Grams and sort
tdm_1gram_df <- ngram_sorted_df(tdm_1gram)
tdm_2gram_df <- ngram_sorted_df(tdm_2gram)
tdm_3gram_df <- ngram_sorted_df(tdm_3gram)
tdm_4gram_df <- ngram_sorted_df(tdm_4gram)
# Save data frames into r-compressed files
quadgram <- data.frame(rows = rownames(tdm_4gram_df), count = tdm_4gram_df$Count)
quadgram$rows <- as.character(quadgram$rows)
quadgram_split <- strsplit(as.character(quadgram$rows),split = " ")
quadgram <- transform(quadgram,
first = sapply(quadgram_split,"[[",1),
second = sapply(quadgram_split,"[[",2),
third = sapply(quadgram_split,"[[",3),
fourth = sapply(quadgram_split,"[[",4))
quadgram <- data.frame(unigram = quadgram$first,
bigram = quadgram$second,
trigram = quadgram$third,
quadgram = quadgram$fourth,
freq = quadgram$count,stringsAsFactors=FALSE)
write.csv(quadgram[quadgram$freq > 1,],"./data/quadgram.csv",row.names=F)
quadgram <- read.csv("./data/quadgram.csv",stringsAsFactors = F)
saveRDS(quadgram,"./app/quadgram.RData")
trigram <- data.frame(rows=rownames(tdm_3gram_df),count=tdm_3gram_df$Count)
trigram$rows <- as.character(trigram$rows)
trigram_split <- strsplit(as.character(trigram$rows),split=" ")
trigram <- transform(trigram,
first = sapply(trigram_split,"[[",1),
second = sapply(trigram_split,"[[",2),
third = sapply(trigram_split,"[[",3))
trigram <- data.frame(unigram = trigram$first,
bigram = trigram$second,
trigram = trigram$third,
freq = trigram$count,stringsAsFactors=FALSE)
write.csv(trigram[trigram$freq > 1,],"./data/trigram.csv",row.names=F)
trigram <- read.csv("./data/trigram.csv",stringsAsFactors = F)
saveRDS(trigram,"./app/trigram.RData")
bigram <- data.frame(rows=rownames(tdm_2gram_df),count=tdm_2gram_df$Count)
bigram$rows <- as.character(bigram$rows)
bigram_split <- strsplit(as.character(bigram$rows),split=" ")
bigram <- transform(bigram,
first = sapply(bigram_split,"[[",1),
second = sapply(bigram_split,"[[",2))
bigram <- data.frame(unigram = bigram$first,
bigram = bigram$second,
freq = bigram$count,stringsAsFactors=FALSE)
write.csv(bigram[bigram$freq > 1,],"./data/bigram.csv",row.names=F)
bigram <- read.csv("./data/bigram.csv",stringsAsFactors = F)
saveRDS(bigram,"./app/bigram.RData")
unigram <- data.frame(rows=rownames(tdm_1gram_df),count=tdm_1gram_df$Count)
unigram$rows <- as.character(unigram$rows)
unigram_split <- strsplit(as.character(unigram$rows),split=" ")
unigram <- transform(unigram,
first = sapply(unigram_split,"[[",1))
unigram <- data.frame(unigram = unigram$first,
freq = unigram$count,
stringsAsFactors=FALSE)
write.csv(unigram[unigram$freq > 1,],"./data/unigram.csv",row.names=F)
unigram <- read.csv("./data/unigram.csv",stringsAsFactors = F)
saveRDS(unigram,"./app/unigram.RData")
runApp('app')
